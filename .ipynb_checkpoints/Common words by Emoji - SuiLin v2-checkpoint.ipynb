{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML, display\n",
    "HTML(\"<style>.container { width:100% !important; }</style>\")\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "matplotlib.rcParams['savefig.dpi'] = 2 * matplotlib.rcParams['savefig.dpi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "#import pandas as pd\n",
    "import numpy as np\n",
    "from Data.sentiment_dict import positive, negative\n",
    "#from sklearn.feature_extraction import DictVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "#pd.options.display.max_colwidth=250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# separate tweet into parts with emojis of interest and the rest\n",
    "def contain_emoji(tweet, emojis):\n",
    "    tweet_emoji = set(tweet).intersection(emojis)\n",
    "    if len(tweet_emoji) == 0:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def filter_emoji(tweet, emojis):\n",
    "    # Return the text without emojis.\n",
    "    text = \"\"\n",
    "    for i in tweet:\n",
    "        if i not in emojis:\n",
    "            text += i\n",
    "    return text\n",
    "\n",
    "def filter_stop(word_list, stop_words):\n",
    "    # Return the words that are not contained in 'stop_words'.\n",
    "    return [word for word in word_list if word.lower() not in stop_words]\n",
    "\n",
    "def convert_to_ngrams(text, n):    # num_ngrams = number of ngrams given user-defined n  e.g. n=1 unigrams; n=2 bigrams\n",
    "    # Convert text to a list of words.\n",
    "    word_list = text.split()\n",
    "    num_ngrams=len(word_list) - n + 1\n",
    "    ngram_list = []\n",
    "    # i = location of ngram's starting word in word list / tweet\n",
    "    for i in range (0, num_ngrams):\n",
    "        # Construct the ngram by chaining the words together.\n",
    "        ngram = word_list[i]\n",
    "        # j is the location of word in the ngram.\n",
    "        for j in range (1, n):\n",
    "            ngram += \" \" + word_list[i + j]\n",
    "        ngram_list.append(ngram)\n",
    "    return ngram_list\n",
    "\n",
    "def update_ngram_count(text, stop_words, n, ngram_count):\n",
    "    # Update 'ngram_count' dictionary with the frequency ngrams that present in 'text'. 'n' is the\n",
    "    # degree of ngrams. If 'n' is 1, then we will filter the unigram using 'stop_words'.\n",
    "    ngram_list = convert_to_ngrams(text, n)\n",
    "    # Only filter stop words for unigrams i.e. ngram_n=1\n",
    "    if n == 1:\n",
    "        ngram_list = filter_stop(ngram_list, stop_words)\n",
    "    for ngram in set(ngram_list):\n",
    "        if ngram not in ngram_count:\n",
    "            ngram_count[ngram] = 1\n",
    "        else: \n",
    "            ngram_count[ngram] += 1\n",
    "                    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# specify the location of the tweets\n",
    "negtweet_file ='./Data/negtweets.txt'\n",
    "postweet_file ='./Data/postweets.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Top 50 Positive Ngrams, where n=', 2)\n",
      "(u'I love', 555)\n",
      "(u'love you', 422)\n",
      "(u'in the', 282)\n",
      "(u'thank you', 228)\n",
      "(u'I was', 219)\n",
      "(u'so much', 207)\n",
      "(u'to be', 191)\n",
      "(u'I just', 189)\n",
      "(u\"I don't\", 185)\n",
      "(u'have a', 170)\n",
      "(u'for the', 161)\n",
      "(u'of the', 153)\n",
      "(u'I have', 145)\n",
      "(u'you so', 144)\n",
      "(u'to the', 141)\n",
      "(u'in my', 137)\n",
      "(u'I know', 136)\n",
      "(u'follow me', 130)\n",
      "(u'the best', 129)\n",
      "(u'is so', 128)\n",
      "(u'to get', 124)\n",
      "(u'this is', 121)\n",
      "(u\"I can't\", 119)\n",
      "(u'and I', 119)\n",
      "(u'to see', 118)\n",
      "(u'all the', 117)\n",
      "(u'if you', 115)\n",
      "(u'going to', 115)\n",
      "(u'I think', 114)\n",
      "(u'on the', 114)\n",
      "(u'is the', 108)\n",
      "(u\"I'm so\", 108)\n",
      "(u'on my', 107)\n",
      "(u'I got', 107)\n",
      "(u'a good', 107)\n",
      "(u'you are', 107)\n",
      "(u'I can', 105)\n",
      "(u'it was', 104)\n",
      "(u'of my', 104)\n",
      "(u'like a', 102)\n",
      "(u'you know', 102)\n",
      "(u'to me', 100)\n",
      "(u'when I', 99)\n",
      "(u'want to', 97)\n",
      "(u'for a', 95)\n",
      "(u'i love', 94)\n",
      "(u'I am', 94)\n",
      "(u'you have', 92)\n",
      "(u'have to', 92)\n",
      "(u'with my', 92)\n",
      "\n",
      "Top 50 Negative Ngrams, where n=2\n",
      "(u'I miss', 375)\n",
      "(u\"I don't\", 353)\n",
      "(u\"I can't\", 347)\n",
      "(u'I just', 342)\n",
      "(u'I need', 336)\n",
      "(u'in the', 335)\n",
      "(u'to be', 333)\n",
      "(u'I want', 294)\n",
      "(u'I have', 272)\n",
      "(u'want to', 252)\n",
      "(u'so much', 248)\n",
      "(u'I was', 242)\n",
      "(u'I love', 233)\n",
      "(u'to go', 220)\n",
      "(u\"I'm so\", 218)\n",
      "(u'to get', 216)\n",
      "(u'need to', 211)\n",
      "(u'going to', 207)\n",
      "(u'go to', 193)\n",
      "(u'have to', 189)\n",
      "(u'I hate', 187)\n",
      "(u'and I', 184)\n",
      "(u'in my', 182)\n",
      "(u'on my', 177)\n",
      "(u'miss you', 172)\n",
      "(u'but I', 170)\n",
      "(u'on the', 163)\n",
      "(u'I feel', 161)\n",
      "(u'I wish', 160)\n",
      "(u'to do', 155)\n",
      "(u'have a', 155)\n",
      "(u'I really', 148)\n",
      "(u'to the', 148)\n",
      "(u'is so', 145)\n",
      "(u'of the', 141)\n",
      "(u'for the', 141)\n",
      "(u'of my', 139)\n",
      "(u'feel like', 137)\n",
      "(u'love you', 137)\n",
      "(u'I can', 134)\n",
      "(u'in a', 130)\n",
      "(u'when I', 129)\n",
      "(u'miss my', 129)\n",
      "(u'right now', 125)\n",
      "(u'I wanna', 124)\n",
      "(u'When you', 123)\n",
      "(u'I had', 123)\n",
      "(u'I know', 122)\n",
      "(u'out of', 122)\n",
      "(u'at the', 120)\n"
     ]
    }
   ],
   "source": [
    "# The words in the tweets that contain positive emoji and their count. We only count the word once even if the word appears\n",
    "# multiple times in a tweet.\n",
    "positive_ngram_count = {}\n",
    "# The words in the tweets that contain positive emoji and their count. We only count the word once even if the word appears\n",
    "# multiple times in a tweet.\n",
    "negative_ngram_count = {}\n",
    "\n",
    "all_emojis = positive + negative\n",
    "#stop_words=stopwords.words(\"english\")\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "added_stop_words = [\"i'm\", \"it's\"]\n",
    "stop_words.update(added_stop_words)\n",
    "\n",
    "ii = 0\n",
    "ngram_n = 3\n",
    "# load all the tweets from negative file\n",
    "with open(postweet_file,'r') as f:\n",
    "    for line in f:\n",
    "        # For testing purpose, only process a limited number of tweets in the file.\n",
    "        #if ii >= 200:\n",
    "         # break\n",
    "        #ii = ii +1\n",
    "        \n",
    "        tweet = line.decode('utf-8')\n",
    "        text_without_emoji = filter_emoji(tweet, all_emojis)\n",
    "        # Process the tweet that contains positive emoji.\n",
    "        if contain_emoji(tweet, positive):\n",
    "            update_ngram_count(text_without_emoji, stop_words, ngram_n, \n",
    "                               positive_ngram_count)\n",
    "                    \n",
    "        # Process the tweet that contains negative emoji.            \n",
    "        if contain_emoji(tweet, negative):\n",
    "            update_ngram_count(text_without_emoji, stop_words, ngram_n, \n",
    "                               negative_ngram_count)\n",
    "\n",
    "# load all the tweets from negative file\n",
    "ii = 0\n",
    "with open(negtweet_file,'r') as f:\n",
    "    for line in f:\n",
    "        # For testing purpose, only process a limited number of tweets in the file.\n",
    "        # if ii >= 200:\n",
    "        #    break\n",
    "        #ii = ii +1\n",
    "        \n",
    "        tweet = line.decode('utf-8')\n",
    "        text_without_emoji = filter_emoji(tweet, all_emojis)\n",
    "        \n",
    "         # Process the tweet that contains positive emoji.\n",
    "        if contain_emoji(tweet, positive):\n",
    "            update_ngram_count(text_without_emoji, stop_words, ngram_n, \n",
    "                               positive_ngram_count)\n",
    "                    \n",
    "        # Process the tweet that contains negative emoji.            \n",
    "        if contain_emoji(tweet, negative):\n",
    "            update_ngram_count(text_without_emoji, stop_words, ngram_n, \n",
    "                               negative_ngram_count)\n",
    "    \n",
    "# Sort the positive and negative words based on their counts.\n",
    "# sorted in descending order using \"reverse = true\"\n",
    "sorted_positive_ngrams = sorted(positive_ngram_count.items(), key=operator.itemgetter(1), reverse=True)\n",
    "#print \"\\nSorted Positive Word Count\"\n",
    "#print sorted_positive_words\n",
    "print (\"Top 50 Positive Ngrams, where n=\", ngram_n)\n",
    "ii = 0\n",
    "for ngram in sorted_positive_ngrams: \n",
    "    if ii >= 50:\n",
    "        break\n",
    "    ii +=1\n",
    "    print ngram\n",
    "\n",
    "sorted_negative_ngrams = sorted(negative_ngram_count.items(), key=operator.itemgetter(1), reverse=True)\n",
    "print (\"\\nTop 50 Negative Ngrams, where n=%d\" % ngram_n)\n",
    "ii = 0\n",
    "for ngram in sorted_negative_ngrams: \n",
    "    if ii >= 50:\n",
    "        break\n",
    "    ii +=1\n",
    "    print ngram\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
